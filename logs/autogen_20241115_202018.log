2024-11-15 20:20:18,458 | MainProcess | MainThread | docker.utils.config | DEBUG | Trying paths: ['/Users/ctavolazzi/.docker/config.json', '/Users/ctavolazzi/.dockercfg']
2024-11-15 20:20:18,459 | MainProcess | MainThread | docker.utils.config | DEBUG | Found file at path: /Users/ctavolazzi/.docker/config.json
2024-11-15 20:20:18,459 | MainProcess | MainThread | docker.auth | DEBUG | Found 'credsStore' section
2024-11-15 20:20:18,474 | MainProcess | MainThread | urllib3.connectionpool | DEBUG | http://localhost:None "GET /version HTTP/1.1" 200 None
2024-11-15 20:20:18,481 | MainProcess | MainThread | urllib3.connectionpool | DEBUG | http://localhost:None "GET /v1.44/images/python:3-slim/json HTTP/1.1" 200 None
2024-11-15 20:20:18,525 | MainProcess | MainThread | urllib3.connectionpool | DEBUG | http://localhost:None "POST /v1.44/containers/create?name=autogen-code-exec-52634d67-7cce-46d3-b39f-00a03594e808 HTTP/1.1" 201 None
2024-11-15 20:20:18,533 | MainProcess | MainThread | urllib3.connectionpool | DEBUG | http://localhost:None "GET /v1.44/containers/4e70259b79a1d1f096288514f186a18dd360dee9161c14923af15bdf152d0d0f/json HTTP/1.1" 200 None
2024-11-15 20:20:18,785 | MainProcess | MainThread | urllib3.connectionpool | DEBUG | http://localhost:None "POST /v1.44/containers/4e70259b79a1d1f096288514f186a18dd360dee9161c14923af15bdf152d0d0f/start HTTP/1.1" 204 0
2024-11-15 20:20:18,896 | MainProcess | MainThread | urllib3.connectionpool | DEBUG | http://localhost:None "GET /v1.44/containers/4e70259b79a1d1f096288514f186a18dd360dee9161c14923af15bdf152d0d0f/json HTTP/1.1" 200 None
2024-11-15 20:20:18,896 | MainProcess | MainThread | AutogenGame | INFO | Setting up agents
2024-11-15 20:20:18,897 | MainProcess | MainThread | httpx | DEBUG | load_ssl_context verify=True cert=None trust_env=True http2=False
2024-11-15 20:20:18,898 | MainProcess | MainThread | httpx | DEBUG | load_verify_locations cafile='/Users/ctavolazzi/.pyenv/versions/3.10.13/lib/python3.10/site-packages/certifi/cacert.pem'
2024-11-15 20:20:18,911 | MainProcess | MainThread | AutogenGame | INFO | Starting Autogen CYOA game
2024-11-15 20:20:18,969 | MainProcess | MainThread | openai._base_client | DEBUG | Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "You are an AI game developer creating a text-based Choose Your Own Adventure game.\nYour task is to:\n1. Create engaging scenarios and choices\n2. Generate markdown files for game content\n3. Implement game state tracking\n4. Create character dialogue based on game state\n5. Log all game actions\n6. Maintain consistent story flow\n\nThe game should:\n- Start with Sam Iker waking from a dream about flying around a skyscraper\n- Have 3 main choices plus an 'other' option for each scene\n- Track game state and character stats\n- Generate dynamic dialogue based on player choices", 'role': 'system'}, {'content': 'Generate the following game components:\n\n1. Create the initial game scene in markdown format\n2. Write a Python class to track game state\n3. Implement a function to handle player choices\n4. Create a logging system for game actions\n\nBegin with the first task: Create the initial game scene in markdown.', 'role': 'user', 'name': 'user_proxy'}], 'model': 'gpt-4', 'seed': 42, 'stream': False, 'temperature': 0.7}}
2024-11-15 20:20:18,997 | MainProcess | MainThread | openai._base_client | DEBUG | Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-15 20:20:18,998 | MainProcess | MainThread | httpcore.connection | DEBUG | connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=120 socket_options=None
2024-11-15 20:20:19,291 | MainProcess | MainThread | httpcore.connection | DEBUG | connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11b122e90>
2024-11-15 20:20:19,292 | MainProcess | MainThread | httpcore.connection | DEBUG | start_tls.started ssl_context=<ssl.SSLContext object at 0x11b099ac0> server_hostname='api.openai.com' timeout=120
2024-11-15 20:20:19,357 | MainProcess | MainThread | httpcore.connection | DEBUG | start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11b0db220>
2024-11-15 20:20:19,358 | MainProcess | MainThread | httpcore.http11 | DEBUG | send_request_headers.started request=<Request [b'POST']>
2024-11-15 20:20:19,359 | MainProcess | MainThread | httpcore.http11 | DEBUG | send_request_headers.complete
2024-11-15 20:20:19,359 | MainProcess | MainThread | httpcore.http11 | DEBUG | send_request_body.started request=<Request [b'POST']>
2024-11-15 20:20:19,359 | MainProcess | MainThread | httpcore.http11 | DEBUG | send_request_body.complete
2024-11-15 20:20:19,359 | MainProcess | MainThread | httpcore.http11 | DEBUG | receive_response_headers.started request=<Request [b'POST']>
2024-11-15 20:20:30,200 | MainProcess | MainThread | httpcore.http11 | DEBUG | receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 16 Nov 2024 04:20:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'gentle-bull-co'), (b'openai-processing-ms', b'9919'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'39765'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'352ms'), (b'x-request-id', b'req_df710750e29a3542289c225de69a91f9'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=TYS4pLmBUKZf9PSmPK7.JROpycekpTvwqYNE.IifAYA-1731730829-1.0.1.1-qJRyTghuf1RgEzoWO6c0HgZPln5KxJwZpHRfrFU5Zym7EH0Bxn57yE.vO40RUOYem00Exh6LehinxcuLxhsbPw; path=/; expires=Sat, 16-Nov-24 04:50:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=8FXAwGbIPca2KlZO9OAtGTb8.zdmIc2rU5T_4f7ldRg-1731730829918-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e34b0183e821666-SJC'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-15 20:20:30,202 | MainProcess | MainThread | httpx | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-15 20:20:30,202 | MainProcess | MainThread | httpcore.http11 | DEBUG | receive_response_body.started request=<Request [b'POST']>
2024-11-15 20:20:30,203 | MainProcess | MainThread | httpcore.http11 | DEBUG | receive_response_body.complete
2024-11-15 20:20:30,203 | MainProcess | MainThread | httpcore.http11 | DEBUG | response_closed.started
2024-11-15 20:20:30,203 | MainProcess | MainThread | httpcore.http11 | DEBUG | response_closed.complete
2024-11-15 20:20:30,204 | MainProcess | MainThread | openai._base_client | DEBUG | HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sat, 16 Nov 2024 04:20:29 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'gentle-bull-co'), ('openai-processing-ms', '9919'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '5000'), ('x-ratelimit-limit-tokens', '40000'), ('x-ratelimit-remaining-requests', '4999'), ('x-ratelimit-remaining-tokens', '39765'), ('x-ratelimit-reset-requests', '12ms'), ('x-ratelimit-reset-tokens', '352ms'), ('x-request-id', 'req_df710750e29a3542289c225de69a91f9'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=TYS4pLmBUKZf9PSmPK7.JROpycekpTvwqYNE.IifAYA-1731730829-1.0.1.1-qJRyTghuf1RgEzoWO6c0HgZPln5KxJwZpHRfrFU5Zym7EH0Bxn57yE.vO40RUOYem00Exh6LehinxcuLxhsbPw; path=/; expires=Sat, 16-Nov-24 04:50:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=8FXAwGbIPca2KlZO9OAtGTb8.zdmIc2rU5T_4f7ldRg-1731730829918-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8e34b0183e821666-SJC'), ('content-encoding', 'br'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-15 20:20:30,204 | MainProcess | MainThread | openai._base_client | DEBUG | request_id: req_df710750e29a3542289c225de69a91f9
2024-11-15 20:20:30,312 | MainProcess | MainThread | openai._base_client | DEBUG | Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "You are an AI game developer creating a text-based Choose Your Own Adventure game.\nYour task is to:\n1. Create engaging scenarios and choices\n2. Generate markdown files for game content\n3. Implement game state tracking\n4. Create character dialogue based on game state\n5. Log all game actions\n6. Maintain consistent story flow\n\nThe game should:\n- Start with Sam Iker waking from a dream about flying around a skyscraper\n- Have 3 main choices plus an 'other' option for each scene\n- Track game state and character stats\n- Generate dynamic dialogue based on player choices", 'role': 'system'}, {'content': 'Generate the following game components:\n\n1. Create the initial game scene in markdown format\n2. Write a Python class to track game state\n3. Implement a function to handle player choices\n4. Create a logging system for game actions\n\nBegin with the first task: Create the initial game scene in markdown.', 'role': 'user', 'name': 'user_proxy'}, {'content': "Sure, let's start by creating the initial scene in markdown:\n\n---\n\n# Scene 1: Awakening from a Dream\n\nSam Iker awakes with a start, feeling the cool rush of air from his dream about flying around a skyscraper. He looks around his small, cluttered apartment, trying to shake off the surreal feeling and orient himself in reality.\n\n- [Option 1: Remember the dream](#Option-1)\n- [Option 2: Get out of bed and start the day](#Option-2)\n- [Option 3: Try to go back to sleep](#Option-3)\n- [Other: Type in your own action](#Other)\n\n## Option 1\nSam closes his eyes, trying to recall the dream in as much detail as possible. It felt so real, he could still feel the wind rushing past him, and the sight of the skyscraper looming below him was still fresh in his mind.\n\n## Option 2\nSam throws off the covers and gets out of bed. He feels a bit groggy, but the memory of the dream is still fresh in his mind. He decides to start his day, hoping that the strange dream isn't a bad omen.\n\n## Option 3\nSam turns over and buries his head under the pillow, trying to fall back asleep. He wants to return to the dream, to soar freely around the skyscraper once more.\n\n## Other\nPlease type your action in the console.\n\n---\n\nWith the first scene set, we can move to the next tasks.", 'role': 'assistant', 'name': 'assistant'}, {'content': '', 'role': 'user', 'name': 'user_proxy'}], 'model': 'gpt-4', 'seed': 42, 'stream': False, 'temperature': 0.7}}
2024-11-15 20:20:30,313 | MainProcess | MainThread | openai._base_client | DEBUG | Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-15 20:20:30,314 | MainProcess | MainThread | httpcore.http11 | DEBUG | send_request_headers.started request=<Request [b'POST']>
2024-11-15 20:20:30,314 | MainProcess | MainThread | httpcore.http11 | DEBUG | send_request_headers.complete
2024-11-15 20:20:30,314 | MainProcess | MainThread | httpcore.http11 | DEBUG | send_request_body.started request=<Request [b'POST']>
2024-11-15 20:20:30,315 | MainProcess | MainThread | httpcore.http11 | DEBUG | send_request_body.complete
2024-11-15 20:20:30,315 | MainProcess | MainThread | httpcore.http11 | DEBUG | receive_response_headers.started request=<Request [b'POST']>
2024-11-15 20:20:38,764 | MainProcess | MainThread | httpcore.http11 | DEBUG | receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 16 Nov 2024 04:20:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'gentle-bull-co'), (b'openai-processing-ms', b'7822'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'39447'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'829ms'), (b'x-request-id', b'req_01471b604e0fc68ee985b9b80d041218'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e34b05cbff41666-SJC'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-15 20:20:38,765 | MainProcess | MainThread | httpx | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-15 20:20:38,765 | MainProcess | MainThread | httpcore.http11 | DEBUG | receive_response_body.started request=<Request [b'POST']>
2024-11-15 20:20:38,766 | MainProcess | MainThread | httpcore.http11 | DEBUG | receive_response_body.complete
2024-11-15 20:20:38,766 | MainProcess | MainThread | httpcore.http11 | DEBUG | response_closed.started
2024-11-15 20:20:38,766 | MainProcess | MainThread | httpcore.http11 | DEBUG | response_closed.complete
2024-11-15 20:20:38,767 | MainProcess | MainThread | openai._base_client | DEBUG | HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sat, 16 Nov 2024 04:20:38 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'gentle-bull-co', 'openai-processing-ms': '7822', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '40000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '39447', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '829ms', 'x-request-id': 'req_01471b604e0fc68ee985b9b80d041218', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e34b05cbff41666-SJC', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-15 20:20:38,767 | MainProcess | MainThread | openai._base_client | DEBUG | request_id: req_01471b604e0fc68ee985b9b80d041218
2024-11-15 20:20:38,825 | MainProcess | MainThread | urllib3.connectionpool | DEBUG | http://localhost:None "POST /v1.44/containers/4e70259b79a1d1f096288514f186a18dd360dee9161c14923af15bdf152d0d0f/exec HTTP/1.1" 201 None
2024-11-15 20:20:38,835 | MainProcess | MainThread | urllib3.connectionpool | DEBUG | http://localhost:None "POST /v1.44/exec/c881579064c15308320e62466bf725ff3ec8ac21606634ce1c60a407d441b230/start HTTP/1.1" 101 0
2024-11-15 20:20:38,987 | MainProcess | MainThread | urllib3.connectionpool | DEBUG | http://localhost:None "GET /v1.44/exec/c881579064c15308320e62466bf725ff3ec8ac21606634ce1c60a407d441b230/json HTTP/1.1" 200 None
2024-11-15 20:20:39,055 | MainProcess | MainThread | openai._base_client | DEBUG | Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "You are an AI game developer creating a text-based Choose Your Own Adventure game.\nYour task is to:\n1. Create engaging scenarios and choices\n2. Generate markdown files for game content\n3. Implement game state tracking\n4. Create character dialogue based on game state\n5. Log all game actions\n6. Maintain consistent story flow\n\nThe game should:\n- Start with Sam Iker waking from a dream about flying around a skyscraper\n- Have 3 main choices plus an 'other' option for each scene\n- Track game state and character stats\n- Generate dynamic dialogue based on player choices", 'role': 'system'}, {'content': 'Generate the following game components:\n\n1. Create the initial game scene in markdown format\n2. Write a Python class to track game state\n3. Implement a function to handle player choices\n4. Create a logging system for game actions\n\nBegin with the first task: Create the initial game scene in markdown.', 'role': 'user', 'name': 'user_proxy'}, {'content': "Sure, let's start by creating the initial scene in markdown:\n\n---\n\n# Scene 1: Awakening from a Dream\n\nSam Iker awakes with a start, feeling the cool rush of air from his dream about flying around a skyscraper. He looks around his small, cluttered apartment, trying to shake off the surreal feeling and orient himself in reality.\n\n- [Option 1: Remember the dream](#Option-1)\n- [Option 2: Get out of bed and start the day](#Option-2)\n- [Option 3: Try to go back to sleep](#Option-3)\n- [Other: Type in your own action](#Other)\n\n## Option 1\nSam closes his eyes, trying to recall the dream in as much detail as possible. It felt so real, he could still feel the wind rushing past him, and the sight of the skyscraper looming below him was still fresh in his mind.\n\n## Option 2\nSam throws off the covers and gets out of bed. He feels a bit groggy, but the memory of the dream is still fresh in his mind. He decides to start his day, hoping that the strange dream isn't a bad omen.\n\n## Option 3\nSam turns over and buries his head under the pillow, trying to fall back asleep. He wants to return to the dream, to soar freely around the skyscraper once more.\n\n## Other\nPlease type your action in the console.\n\n---\n\nWith the first scene set, we can move to the next tasks.", 'role': 'assistant', 'name': 'assistant'}, {'content': '', 'role': 'user', 'name': 'user_proxy'}, {'content': "Great, let's move on to the next task which is writing a Python class to track game state. Here's a basic implementation:\n\n```python\nclass GameState:\n    def __init__(self):\n        self.scene = 1\n        self.health = 100\n        self.energy = 100\n        self.mood = 'Neutral'\n        self.recall_dream = False\n        self.actions_taken = []\n\n    def update_state(self, action):\n        self.actions_taken.append(action)\n        if action == 'Option 1':\n            self.recall_dream = True\n        elif action == 'Option 2':\n            self.energy -= 10\n        elif action == 'Option 3':\n            self.energy += 10\n\n    def get_state(self):\n        return {\n            'Scene': self.scene,\n            'Health': self.health,\n            'Energy': self.energy,\n            'Mood': self.mood,\n            'Recall Dream': self.recall_dream,\n            'Actions Taken': self.actions_taken\n        }\n```\n\nThis class has a method `update_state` to update the game state based on the chosen action, and a method `get_state` to retrieve the current game state.\n\nNext, we need to implement a function to handle player choices.", 'role': 'assistant', 'name': 'assistant'}, {'content': 'exitcode: 0 (execution succeeded)\nCode output: ', 'role': 'user', 'name': 'user_proxy'}], 'model': 'gpt-4', 'seed': 42, 'stream': False, 'temperature': 0.7}}
2024-11-15 20:20:39,056 | MainProcess | MainThread | openai._base_client | DEBUG | Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-15 20:20:39,057 | MainProcess | MainThread | httpcore.http11 | DEBUG | send_request_headers.started request=<Request [b'POST']>
2024-11-15 20:20:39,057 | MainProcess | MainThread | httpcore.http11 | DEBUG | send_request_headers.complete
2024-11-15 20:20:39,058 | MainProcess | MainThread | httpcore.http11 | DEBUG | send_request_body.started request=<Request [b'POST']>
2024-11-15 20:20:39,058 | MainProcess | MainThread | httpcore.http11 | DEBUG | send_request_body.complete
2024-11-15 20:20:39,058 | MainProcess | MainThread | httpcore.http11 | DEBUG | receive_response_headers.started request=<Request [b'POST']>
2024-11-15 20:20:49,208 | MainProcess | MainThread | httpcore.http11 | DEBUG | receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 16 Nov 2024 04:20:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'gentle-bull-co'), (b'openai-processing-ms', b'9698'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'39151'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'1.273s'), (b'x-request-id', b'req_3d457774494c8be7bbbfa1de032a5922'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e34b093889e1666-SJC'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-15 20:20:49,209 | MainProcess | MainThread | httpx | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-15 20:20:49,209 | MainProcess | MainThread | httpcore.http11 | DEBUG | receive_response_body.started request=<Request [b'POST']>
2024-11-15 20:20:49,210 | MainProcess | MainThread | httpcore.http11 | DEBUG | receive_response_body.complete
2024-11-15 20:20:49,210 | MainProcess | MainThread | httpcore.http11 | DEBUG | response_closed.started
2024-11-15 20:20:49,210 | MainProcess | MainThread | httpcore.http11 | DEBUG | response_closed.complete
2024-11-15 20:20:49,210 | MainProcess | MainThread | openai._base_client | DEBUG | HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sat, 16 Nov 2024 04:20:49 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'gentle-bull-co', 'openai-processing-ms': '9698', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '40000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '39151', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '1.273s', 'x-request-id': 'req_3d457774494c8be7bbbfa1de032a5922', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e34b093889e1666-SJC', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-15 20:20:49,210 | MainProcess | MainThread | openai._base_client | DEBUG | request_id: req_3d457774494c8be7bbbfa1de032a5922
2024-11-15 20:20:49,260 | MainProcess | MainThread | urllib3.connectionpool | DEBUG | http://localhost:None "POST /v1.44/containers/4e70259b79a1d1f096288514f186a18dd360dee9161c14923af15bdf152d0d0f/exec HTTP/1.1" 201 None
2024-11-15 20:20:49,271 | MainProcess | MainThread | urllib3.connectionpool | DEBUG | http://localhost:None "POST /v1.44/exec/bda994ff9ebdc55154161ef7b552421df258ce5b66afec6c134f1e9f7e13d734/start HTTP/1.1" 101 0
2024-11-15 20:20:49,350 | MainProcess | MainThread | urllib3.connectionpool | DEBUG | http://localhost:None "GET /v1.44/exec/bda994ff9ebdc55154161ef7b552421df258ce5b66afec6c134f1e9f7e13d734/json HTTP/1.1" 200 None
2024-11-15 20:20:49,358 | MainProcess | MainThread | urllib3.connectionpool | DEBUG | http://localhost:None "POST /v1.44/containers/4e70259b79a1d1f096288514f186a18dd360dee9161c14923af15bdf152d0d0f/exec HTTP/1.1" 201 None
2024-11-15 20:20:49,367 | MainProcess | MainThread | urllib3.connectionpool | DEBUG | http://localhost:None "POST /v1.44/exec/fc376723251f61604ca8012fa39b2a8620c4c14dd5a84c1fd020998d90dec510/start HTTP/1.1" 101 0
2024-11-15 20:20:49,604 | MainProcess | MainThread | urllib3.connectionpool | DEBUG | http://localhost:None "GET /v1.44/exec/fc376723251f61604ca8012fa39b2a8620c4c14dd5a84c1fd020998d90dec510/json HTTP/1.1" 200 None
2024-11-15 20:20:49,612 | MainProcess | MainThread | urllib3.connectionpool | DEBUG | http://localhost:None "GET /v1.44/containers/autogen-code-exec-52634d67-7cce-46d3-b39f-00a03594e808/json HTTP/1.1" 200 None
2024-11-15 20:20:51,290 | MainProcess | MainThread | urllib3.connectionpool | DEBUG | http://localhost:None "GET /v1.44/containers/autogen-code-exec-52634d67-7cce-46d3-b39f-00a03594e808/json HTTP/1.1" 200 None
2024-11-15 20:20:59,785 | MainProcess | MainThread | urllib3.connectionpool | DEBUG | http://localhost:None "POST /v1.44/containers/4e70259b79a1d1f096288514f186a18dd360dee9161c14923af15bdf152d0d0f/stop HTTP/1.1" 204 0
2024-11-15 20:20:59,900 | MainProcess | MainThread | httpcore.connection | DEBUG | close.started
2024-11-15 20:20:59,901 | MainProcess | MainThread | httpcore.connection | DEBUG | close.complete
